{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f69b336b",
   "metadata": {},
   "source": [
    "<hr style=\"border:0.1px solid gray\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f629d5c",
   "metadata": {},
   "source": [
    "# <center style='color:Red'> COSC2753 - Machine Learning </center> \n",
    "## <center style='color:Red'> Assignment 2 - Classify Images of Colon Cancer </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39870a75",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#-COSC2753---Machine-Learning-\" data-toc-modified-id=\"-COSC2753---Machine-Learning--1\"><center style=\"color:Red\"> COSC2753 - Machine Learning </center></a></span><ul class=\"toc-item\"><li><span><a href=\"#-Assignment-2---Classify-Images-of-Colon-Cancer-\" data-toc-modified-id=\"-Assignment-2---Classify-Images-of-Colon-Cancer--1.1\"><center style=\"color:Red\"> Assignment 2 - Classify Images of Colon Cancer </center></a></span></li></ul></li><li><span><a href=\"#Main-Task\" data-toc-modified-id=\"Main-Task-2\">Main Task</a></span></li><li><span><a href=\"#1.-Import-libraries-and-setting-up-environment\" data-toc-modified-id=\"1.-Import-libraries-and-setting-up-environment-3\">1. Import libraries and setting up environment</a></span></li><li><span><a href=\"#2.-Import-Dataset\" data-toc-modified-id=\"2.-Import-Dataset-4\">2. Import Dataset</a></span></li><li><span><a href=\"#3.-Exploratory-Data-Analysis-(EDA)\" data-toc-modified-id=\"3.-Exploratory-Data-Analysis-(EDA)-5\">3. Exploratory Data Analysis (EDA)</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.1.-Process-the-data\" data-toc-modified-id=\"3.1.-Process-the-data-5.1\">3.1. Process the data</a></span></li><li><span><a href=\"#3.2.-Data-Analysis-and-Visualiztion\" data-toc-modified-id=\"3.2.-Data-Analysis-and-Visualiztion-5.2\">3.2. Data Analysis and Visualiztion</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.2.1.-Correlation-and-Correlation-Matrix\" data-toc-modified-id=\"3.2.1.-Correlation-and-Correlation-Matrix-5.2.1\">3.2.1. Correlation and Correlation Matrix</a></span></li><li><span><a href=\"#3.2.2.-Data-Distribution\" data-toc-modified-id=\"3.2.2.-Data-Distribution-5.2.2\">3.2.2. Data Distribution</a></span></li><li><span><a href=\"#Countplot\" data-toc-modified-id=\"Countplot-5.2.3\">Countplot</a></span></li><li><span><a href=\"#Histogram\" data-toc-modified-id=\"Histogram-5.2.4\">Histogram</a></span></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-5.2.5\">Conclusion</a></span></li></ul></li><li><span><a href=\"#3.3.-Data-Preparation\" data-toc-modified-id=\"3.3.-Data-Preparation-5.3\">3.3. Data Preparation</a></span></li></ul></li><li><span><a href=\"#4.-Models\" data-toc-modified-id=\"4.-Models-6\">4. Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#4.1-Convolutional-neural-network\" data-toc-modified-id=\"4.1-Convolutional-neural-network-6.1\">4.1 Convolutional neural network</a></span><ul class=\"toc-item\"><li><span><a href=\"#4.1.1-Baseline-model\" data-toc-modified-id=\"4.1.1-Baseline-model-6.1.1\">4.1.1 Baseline model</a></span></li><li><span><a href=\"#4.1.2-Hyperparameter-tuning\" data-toc-modified-id=\"4.1.2-Hyperparameter-tuning-6.1.2\">4.1.2 Hyperparameter tuning</a></span><ul class=\"toc-item\"><li><span><a href=\"#I.-Layers-tuning\" data-toc-modified-id=\"I.-Layers-tuning-6.1.2.1\">I. Layers tuning</a></span></li></ul></li><li><span><a href=\"#4.1.3-Final-model\" data-toc-modified-id=\"4.1.3-Final-model-6.1.3\">4.1.3 Final model</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aa65e3",
   "metadata": {},
   "source": [
    "**Group Number:** 8\n",
    "\n",
    "**Student 1:** Ngo Quang Khai - s3836387 \n",
    "\n",
    "**Student 2:** Nguyen Quoc Minh - s3758994\n",
    "\n",
    "**Student 3:** Bui Thanh Huy - s3740934\n",
    "\n",
    "**Student 4:** Tran Vinh Khang - s3855823\n",
    "\n",
    "**Student 5:** Le Trong Hung - s3805504\n",
    "\n",
    "**Lecturer:** Dr. Bao Nguyen\n",
    "\n",
    "**Due Date:** May 14th, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf7d6af",
   "metadata": {},
   "source": [
    "<hr style=\"border:0.1px solid gray\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d958fcfd",
   "metadata": {},
   "source": [
    "# Main Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b10ae1e",
   "metadata": {},
   "source": [
    "- **Task 1**: Classify images according to whether given cell image represents a cancerous cells or not (isCancerous)\n",
    "\n",
    "\n",
    "- **Task 2**: Classify images according to cell-type, such as: fibroblast, inflammatory, epithelial or others.\n",
    "\n",
    "\n",
    "- **Extra task**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cc28c3",
   "metadata": {},
   "source": [
    "# 1. Import libraries and setting up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "968c270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install keras\n",
    "# !pip install opencv-python\n",
    "# !pip install bayesian-optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45899c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn as sk\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from math import floor\n",
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import StratifiedKFold,GridSearchCV\n",
    "\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "LeakyReLU = LeakyReLU(alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdcf75fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.6.0\n",
      "CV2 version: 4.5.5\n"
     ]
    }
   ],
   "source": [
    "#It is important to check the version of these libraries to make sure that implement the latest method.\n",
    "print('Tensorflow version:', tf.__version__)\n",
    "print('CV2 version:', cv2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c253d70",
   "metadata": {},
   "source": [
    "# 2. Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a1ee400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data_labels_mainData.csv into a DataFrame\n",
    "main_data = pd.read_csv('data_labels_mainData.csv')\n",
    "\n",
    "# Import data_labels_extraData.csv into a DataFrame\n",
    "extra_data = pd.read_csv('data_labels_extraData.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d64513",
   "metadata": {},
   "source": [
    "# 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520b23ab",
   "metadata": {},
   "source": [
    "## 3.1. Process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7620550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe of main_data: \n",
      "       InstanceID  patientID  ImageName cellTypeName  cellType  isCancerous\n",
      "0          22405          1  22405.png   fibroblast         0            0\n",
      "1          22406          1  22406.png   fibroblast         0            0\n",
      "2          22407          1  22407.png   fibroblast         0            0\n",
      "3          22408          1  22408.png   fibroblast         0            0\n",
      "4          22409          1  22409.png   fibroblast         0            0\n",
      "...          ...        ...        ...          ...       ...          ...\n",
      "9891        1625         60   1625.png   epithelial         2            1\n",
      "9892        1626         60   1626.png   epithelial         2            1\n",
      "9893        1627         60   1627.png   epithelial         2            1\n",
      "9894        1628         60   1628.png   epithelial         2            1\n",
      "9895        1629         60   1629.png   epithelial         2            1\n",
      "\n",
      "[9896 rows x 6 columns] \n",
      "\n",
      "Dataframe of extra_data: \n",
      "        InstanceID  patientID  ImageName  isCancerous\n",
      "0           12681         61  12681.png            0\n",
      "1           12682         61  12682.png            0\n",
      "2           12683         61  12683.png            0\n",
      "3           12684         61  12684.png            0\n",
      "4           12685         61  12685.png            0\n",
      "...           ...        ...        ...          ...\n",
      "10379       20028         99  20028.png            0\n",
      "10380       20029         99  20029.png            0\n",
      "10381       20030         99  20030.png            0\n",
      "10382       20031         99  20031.png            0\n",
      "10383       20032         99  20032.png            0\n",
      "\n",
      "[10384 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#See the data frame of main_data\n",
    "print(\"Dataframe of main_data: \\n\", main_data, \"\\n\")\n",
    "\n",
    "#See the data frame of extra_data\n",
    "print(\"Dataframe of extra_data: \\n\", extra_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ca9884",
   "metadata": {},
   "source": [
    "**=>** Next, we will check if the data have any null values and datatype of each columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e93d75f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9896 entries, 0 to 9895\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   InstanceID    9896 non-null   int64 \n",
      " 1   patientID     9896 non-null   int64 \n",
      " 2   ImageName     9896 non-null   object\n",
      " 3   cellTypeName  9896 non-null   object\n",
      " 4   cellType      9896 non-null   int64 \n",
      " 5   isCancerous   9896 non-null   int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 464.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "InstanceID      0\n",
       "patientID       0\n",
       "ImageName       0\n",
       "cellTypeName    0\n",
       "cellType        0\n",
       "isCancerous     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_data.info()\n",
    "main_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc7dc0b6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10384 entries, 0 to 10383\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   InstanceID   10384 non-null  int64 \n",
      " 1   patientID    10384 non-null  int64 \n",
      " 2   ImageName    10384 non-null  object\n",
      " 3   isCancerous  10384 non-null  int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 324.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "InstanceID     0\n",
       "patientID      0\n",
       "ImageName      0\n",
       "isCancerous    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_data.info()\n",
    "extra_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5553755d",
   "metadata": {},
   "source": [
    "**=>** Since our data is no missing/null value and properly formatted, we will move on to analyzing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8ff5d3",
   "metadata": {},
   "source": [
    "## 3.2. Data Analysis and Visualiztion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ffbe57",
   "metadata": {},
   "source": [
    "Based on the information provided by the biomedical company as well as the DataFrames in **section 3.1** above. We are aware of:\n",
    "- The **main_data** contains both **cellType (0 to 3)** and **isCancerous (0 and 1)** columns. In there, **cellType** values 0 to 3 represent fibroblast, inflammatory, epithelial, and miscellaneous cell types respectively based on the **cellTypeName** column. In addition, **isCancerous** values 0 and 1 represent colon cells with non-Cancer and Cancer.\n",
    "\n",
    "\n",
    "- The **extra_data** only contains **isCancerous (0 and 1)** column.\n",
    "\n",
    "**=>** Therefore, we choose the **isCancerous** attribute as the target column because both **main_data** and **extra_data** have the column **isCancerous**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecfa939",
   "metadata": {},
   "source": [
    "### 3.2.1. Correlation and Correlation Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e95090",
   "metadata": {},
   "source": [
    "Firstly, we will draw the correlation matrix to find out any relationship between **isCancerous** column with the others\n",
    "columns in **main_data**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a690da07",
   "metadata": {},
   "source": [
    "**Analysis**\n",
    "\n",
    "As we can see from the matrix above, most of the attributes do not correlate with **isCancerous** much are **InstanceID** (-0.44), **patientID** (-0.0012). Since these attributes do not affect much to isCancerous attribute, we will not use these attributes to train our model. Applying these two attributes to train the model can cause noise and overcomplicated issue to our prediction model.\n",
    "\n",
    "**=>** There is only attribute **cellType** with 0.44 has high impact on the attribute 'isCancerous'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acfa007",
   "metadata": {},
   "source": [
    "### 3.2.2. Data Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4f6a62",
   "metadata": {},
   "source": [
    "### Countplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647541d8",
   "metadata": {},
   "source": [
    "**Analysis**\n",
    "- The first countplot shows us there 4 different types of cell: 0, 1, 2, 3. The first type of cell is 0 has approximately 1900, the second type of cell is 2 has approximately 2600, the third one is 4100 and last one is 1500.\n",
    "\n",
    "\n",
    "- The second countplot shows us number of cells that are cancer and not. In the first column is 0 represent the cell that are not cancerous, and 1 represent the cell that are cancerous. There are approximately 5900 cells that are not cancerous and 4200 cells that are cancerous in our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b791a84",
   "metadata": {},
   "source": [
    "### Histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f79792",
   "metadata": {},
   "source": [
    "**Analysis**\n",
    "\n",
    "Looking at these two histograms, we can see that 'cellType' 0, 1, and 3 are not cancerous. Meanwhile only 'cellType' 2 is cancerous."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd878ff",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "- In **main_data**, only the attribute **cellType** continue to be our strongest candidate for to influence our model when it has high impact on our target attribute is **isCancerous**.\n",
    "\n",
    "\n",
    "- Attributes such as **InstanceID** and **patientID** might create a lot of noise in our model. \n",
    "\n",
    "\n",
    "- There are 4 types of cells: 0, 1, 2, 3. Only cell type number 2 is cancerous while others are not cancerous.\n",
    "\n",
    "\n",
    "- We expect the the model would predict class 0 more accurately than class 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e43f450",
   "metadata": {},
   "source": [
    "## 3.3. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ac75d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape task 1: (6927, 2)\n",
      "Validation data shape task 1: (2969, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "traindata, validata = train_test_split(main_data[['ImageName','cellType']], \n",
    "                                              test_size=0.3, random_state=9, stratify = main_data[['cellType']])                                        \n",
    "\n",
    "print('Training data shape task 1:', traindata.shape)\n",
    "print('Validation data shape task 1:', validata.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd2afeae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1242     4988.png\n",
      "4946    18534.png\n",
      "4936    18523.png\n",
      "2094    15839.png\n",
      "8858    13948.png\n",
      "          ...    \n",
      "9667    17698.png\n",
      "9217    12241.png\n",
      "6611     9991.png\n",
      "235     18639.png\n",
      "8818    13908.png\n",
      "Name: ImageName, Length: 6927, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(traindata['ImageName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8e9c4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a a function to add image according to the name given from the list\n",
    "\n",
    "def GetImage(directory):\n",
    "    images=[]\n",
    "    for name in tqdm(directory, desc=\"Adding images\"):\n",
    "        image = cv2.imread(\"patch_images/\"+name)\n",
    "        image = Image.fromarray(image,'RGB')\n",
    "        images.append(np.array(image))\n",
    "    result = np.array(images)\n",
    "    print(\"\\ngetImage COMPLETED!\")\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f3f247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get images ready by loading and preprocessing.\n",
    "def get_images_ready(n_classes=10):\n",
    "    (trainX, trainy), (_, _) = load_data()\n",
    "    X = np.expand_dims(trainX, axis=-1)\n",
    "    X = X.astype('float32')\n",
    "    X = X/255.  # scale from [0,255] to [0,1]  \n",
    "    print(X.shape, trainy.shape)\n",
    "    return [X, trainy]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26f8222",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pick a subset of images. \n",
    "num_images = 120\n",
    "def select_subset_images(dataset, n_samples=num_images, n_classes=10):\n",
    " \tX, y = dataset\n",
    " \tX_list, y_list = list(), list()\n",
    " \tn_per_class = int(n_samples / n_classes) #Number of samples per class. \n",
    " \tfor i in range(n_classes):\n",
    "        X_with_class = X[y == i] # get all images for this class\n",
    "        ix = randint(0, len(X_with_class), n_per_class) # choose random images for each class\n",
    "        [X_list.append(X_with_class[j]) for j in ix] # add to list\n",
    "        [y_list.append(i) for j in ix]\n",
    "    return np.asarray(X_list), np.asarray(y_list) #Returns a list of 2 numpy arrays corresponding to X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7ac7950",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to generate sample to fix the Imblance of the dataset\n",
    "def GenerateSample(X,Y):\n",
    "    ros = RandomOverSampler(random_state = 1)\n",
    "    x, y = ros.fit_resample(X.values.reshape(-1,1), Y)\n",
    "    x = x.flatten()\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52c3735",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \n",
    "X, Y = select_subset_images(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8e2fb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset:\n",
      " 2    2855\n",
      "1    1780\n",
      "0    1322\n",
      "3     970\n",
      "Name: cellType, dtype: int64\n",
      "Sampled Dataset:\n",
      " 2    2855\n",
      "3    2855\n",
      "1    2855\n",
      "0    2855\n",
      "Name: cellType, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding images: 100%|███████████████████████████████████████████████████████████| 11420/11420 [00:02<00:00, 5688.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "getImage COMPLETED!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding images: 100%|█████████████████████████████████████████████████████████████| 2969/2969 [00:00<00:00, 5417.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "getImage COMPLETED!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x2_train = train_task2['ImageName']\n",
    "y2_train = train_task2['cellType']\n",
    "print(\"Original Dataset:\\n\",y2_train.value_counts())\n",
    "\n",
    "#Generate sample\n",
    "x2_train, y2_train = GenerateSample(x2_train,y2_train)\n",
    "print(\"Sampled Dataset:\\n\",y2_train.value_counts())\n",
    "x2_train = GetImage(x2_train)\n",
    "\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]\n",
    "\n",
    "x2_val = val_task2['ImageName']\n",
    "x2_val = GetImage(x2_val)\n",
    "\n",
    "y2_val = val_task2['cellType']\n",
    "\n",
    "x2_test,x2_val,y2_test,y2_val = train_test_split(x2_val, y2_val,\n",
    "                                              test_size=0.5, random_state=9, stratify = y2_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a67fa11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TASK 2 SHAPE:\n",
      "x1 shape: (11420, 27, 27, 3)\n",
      "y1 shape: (11420,)\n",
      "VALIDATION SHAPE:\n",
      "x1 shape: (1485, 27, 27, 3)\n",
      "y1 shape: (1485,)\n",
      "TEST SHAPE:\n",
      "x1 shape: (1484, 27, 27, 3)\n",
      "y1 shape: (1484,)\n"
     ]
    }
   ],
   "source": [
    "print(\"TASK 2 SHAPE:\")\n",
    "print(\"x1 shape:\", x2_train.shape)\n",
    "print(\"y1 shape:\", y2_train.shape)\n",
    "print(\"VALIDATION SHAPE:\")\n",
    "print(\"x1 shape:\", x2_val.shape)\n",
    "print(\"y1 shape:\", y2_val.shape)\n",
    "print(\"TEST SHAPE:\")\n",
    "print(\"x1 shape:\", x2_test.shape)\n",
    "print(\"y1 shape:\", y2_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "145b17be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train_scaled = x2_train / 255\n",
    "X2_val_scaled = x2_val / 255\n",
    "X2_test_scaled = x2_test / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4861c72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential(\n",
    "  [\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\",input_shape=(27,27,3)),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d363c85",
   "metadata": {},
   "source": [
    "# 4. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cce0ad",
   "metadata": {},
   "source": [
    "## 4.1 Convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8aa6ab",
   "metadata": {},
   "source": [
    "### 4.1.1 Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5f0f68",
   "metadata": {},
   "source": [
    "model = Sequential([\n",
    "    data_augmentation,\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Dropout(0.2),\n",
    "    \n",
    "    layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(l=0.01),padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(l=0.01),padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    \n",
    "    layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(l=0.01),padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(l=0.01),padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Dropout(0.4),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, kernel_regularizer=l2(l=0.01), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(512, kernel_regularizer=l2(l=0.01), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "opt = Adam(lr=0.0005, beta_1=0.4, beta_2=0.444, decay=1.0e-6, amsgrad=True)\n",
    "model.compile(optimizer=opt , loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65d34d3",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='accuracy', min_delta=0.001, patience=10, verbose=1, mode='auto'),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"task2/task2_weights.{epoch:02d}-valloss.{val_loss:.2f}.h5\",\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1), cooldown=0, patience=6, min_lr=0.5e-15) \n",
    "]\n",
    "\n",
    "EPOCHS = 500\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "with tf.device('/GPU:0'): \n",
    "    history = model.fit(X2_train_scaled, y2_train,\n",
    "                    validation_data=(X2_val_scaled, y2_val), \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    epochs=EPOCHS, \n",
    "                    verbose=1,\n",
    "                    callbacks=my_callbacks)\n",
    "\n",
    "print(\"---  Training time in seconds ---%s \" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a738ce",
   "metadata": {},
   "source": [
    "\n",
    "scores = model.evaluate(X2_val_scaled, y2_val, verbose=1)\n",
    "print('Validation loss:', scores[0])\n",
    "print('Validation accuracy:', scores[1])\n",
    "print('Max Validation accuracy:', max(history.history['accuracy']))\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d98370",
   "metadata": {},
   "source": [
    "predict=model.predict(X2_test_scaled)\n",
    "classes=np.argmax(predict,axis=1)\n",
    "\n",
    "print(classification_report(y2_test, classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d9e677",
   "metadata": {},
   "source": [
    "class_names = [\"fibroblast\",\"inflammatory\",\"epithelial\",\"others\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398ddef4",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "batch_predict = model.predict (X2_test_scaled)\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i+1)\n",
    "    first_image = X2_test_scaled[i]\n",
    "    first_label = int(y2_test.iloc[i])\n",
    "    plt.imshow(first_image)\n",
    "    confidence = round(100 * (np.max(batch_predict[i][0])), 2)\n",
    "    actual_class= class_names[first_label]\n",
    "    predicted_class = class_names[np.argmax(batch_predict[i])]\n",
    "    \n",
    "    plt.title(f\"Actual: {actual_class},\\n Predicted: {predicted_class}.\\n Confidence: {confidence}%\")\n",
    "    plt.axis(\"off\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b969744",
   "metadata": {},
   "source": [
    "### 4.1.2 Hyperparameter tuning\n",
    "#### I. Layers tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da74cd95",
   "metadata": {},
   "source": [
    "### 4.1.3 Final model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319e6130",
   "metadata": {},
   "source": [
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c460916a",
   "metadata": {},
   "source": [
    " model.load_weights(\"task2_weights.111-0.76.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "383.984px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
